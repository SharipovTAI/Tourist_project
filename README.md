AI-чат-бот по заповедникам России
(Django + LLaMA + RAG, офлайн)

Локальный AI-чат-бот, который отвечает на вопросы о заповедниках России
строго на основе загруженного JSON-файла, без облачных API и интернета.

Проект реализует подход RAG (Retrieval-Augmented Generation)
на базе mistral-7b-instruct-v0.2.Q4_K_M и SentenceTransformer.


Описание проекта:

Проект представляет собой Django-приложение с локальной LLM, предназначенное для:
ответов на вопросы о заповедниках;
анализа геополитических факторов;
демонстрации работы локальных языковых моделей;
учебных и исследовательских целей.

Модель не обучается и не имеет собственной базы знаний —
она отвечает исключительно на основе переданного контекста.


Цели:

Реализовать RAG без облачных сервисов
Исключить галлюцинации модели
Обеспечить полный контроль над источником информации
Использовать open-source стек


Технологический стек:
Backend:
   Python 3.10.x
   Django
AI / ML:
   mistral-7b-instruct-v0.2.Q4_K_M (GGUF)
   llama-cpp-python
   SentenceTransformer (all-MiniLM-L6-v2)

Архитектура:
Пользователь
   ↓
Django (views.py)
   ↓
Поиск релевантных блоков (SentenceTransformer)
   ↓
Формирование prompt
   ↓
LLaMA (llama-cpp-python)
   ↓
Ответ



Структура репозитория:
tourist_project/
│
├── homepage/
│   ├── views.py           # Основная логика RAG
│   ├── urls.py
│   └── templates/
│   
│
├── Llama_project/
│   └── models/
│       └── mistral-7b-instruct-v0.2.Q4_K_M.gguf
│
├── venv/
├── manage.py
└── README.md



Источник данных:
Все знания хранятся в одном файле: reserves_database.json
Он содержит:
описание Таймырского заповедника;
данные о других заповедниках России;
геополитические факторы;
исторический и научный контекст.

Модель не читает файл напрямую —
текст извлекается и передаётся через prompt.


Как это работает (RAG):
   Word-файл разбивается на смысловые блоки
   Для каждого блока создаётся embedding
   Вопрос пользователя тоже преобразуется в embedding
   Выбираются наиболее релевантные блоки
   Только они передаются в LLaMA
Таким образом:
   модель не «придумывает»;
   ответы воспроизводимы;
   источник информации прозрачен.


Установка и запуск:
python --version -> Python 3.10.x
pip install django llama-cpp-python sentence-transformers python-docx numpy
python manage.py runserver

Известные проблемы:
1) Галлюцинация;
При плохой структуре JSON-файла:
2) Возможны логические ошибки;

Планы по улучшению
Кэширование embedding’ов
Улучшенная тематическая фильтрация
Админ-панель для редактирования данных
История диалогов

Назначение проекта:
Проект подходит для:
курсовых и дипломных работ
демонстрации RAG-подхода
экспериментов с локальными LLM
изучения Django + AI


Автор:
Проект разработан в учебных и исследовательских целях.
Все используемые модели и библиотеки — open-source.
